{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#ExtremeHelp.ipynb\n",
        "## ExtremeHelp: Modelo de Visão Computacional para Identificação de Desastres\n",
        "\n",
        "**Introdução:**\n",
        "Este notebook demonstra um modelo de classificação de imagens para identificar cenários de desastres (ex: enchente, incêndio, normal) como parte do projeto ExtremeHelp. O objetivo é analisar imagens para auxiliar na identificação e classificação de áreas afetadas, fornecendo informações que podem ser usadas para alertas e otimização de ajuda no aplicativo.\n",
        "\n",
        "**Passos do Notebook:**\n",
        "1.  Configuração do Ambiente e Importações Essenciais\n",
        "2.  Definição de Parâmetros e Caminhos para o Dataset\n",
        "3.  Preparação dos Geradores de Dados (ImageDataGenerator)\n",
        "4.  Visualização de Amostras de Imagens (Opcional)\n",
        "5.  Construção do Modelo de Rede Neural Convolucional (CNN)\n",
        "6.  Compilação e Treinamento do Modelo\n",
        "7.  Avaliação do Desempenho do Modelo\n",
        "8.  Teste do Modelo com Novas Imagens (Exemplo)"
      ],
      "metadata": {
        "id": "h6F_A4j1QQ5b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Configuração do Ambiente e Importações Essenciais\n",
        "\n",
        "Nesta seção, importamos as bibliotecas necessárias para o projeto:\n",
        "\n",
        "- **TensorFlow e Keras**: Para construir e treinar a rede neural.\n",
        "- **NumPy**: Para manipulação numérica eficiente.\n",
        "- **Matplotlib e Seaborn**: Para visualização de dados e resultados.\n",
        "- **OS**: Para interagir com o sistema de arquivos (gerenciar caminhos e diretórios)."
      ],
      "metadata": {
        "id": "NoO6HBQqkK5_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator # Para carregar imagens e data augmentation\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint # Callbacks para otimizar o treinamento\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os # Para interagir com o sistema de arquivos e caminhos\n",
        "\n",
        "print(f\"TensorFlow Version: {tf.__version__}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "foMemaSkQiR7",
        "outputId": "5693aa16-1451-4b2d-be62-201f0dca590b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow Version: 2.18.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# 2. Definição de Parâmetros e Caminhos para o Dataset\n",
        "\n",
        "Aqui, definimos constantes que serão usadas ao longo do notebook. Isso inclui:\n",
        "\n",
        "- **Dimensões das imagens**: `IMAGE_WIDTH`, `IMAGE_HEIGHT`, `IMAGE_SIZE`.\n",
        "- **Número de canais de cor**: `IMAGE_CHANNELS` (`3` para RGB, `1` para escala de cinza).\n",
        "- **Tamanho do batch para treinamento**: `BATCH_SIZE`.\n",
        "- **Número máximo de épocas de treinamento**: `EPOCHS`.\n",
        "- **Número de classes (`NUM_CLASSES`)**: Será determinado dinamicamente a partir dos dados carregados."
      ],
      "metadata": {
        "id": "8XxIb3q3kQjw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parâmetros de configuração das imagens e do treinamento\n",
        "IMAGE_WIDTH = 128\n",
        "IMAGE_HEIGHT = 128\n",
        "IMAGE_SIZE = (IMAGE_WIDTH, IMAGE_HEIGHT)\n",
        "IMAGE_CHANNELS = 3\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 25\n",
        "\n",
        "# Ou se você fez upload para o ambiente do Colab:\n",
        "BASE_DIR = 'meu_dataset_desastres'\n",
        "\n",
        "TRAIN_DIR = os.path.join(BASE_DIR, 'train')\n",
        "VALIDATION_DIR = os.path.join(BASE_DIR, 'validation')\n",
        "\n",
        "# Verificar se os diretórios do dataset existem.\n",
        "\n",
        "if not os.path.exists(BASE_DIR):\n",
        "    print(f\"ERRO: O diretório base do dataset '{BASE_DIR}' não foi encontrado.\")\n",
        "    print(\"Por favor, crie este diretório, organize suas imagens de treino e validação dentro dele\")\n",
        "    print(\"conforme a estrutura descrita acima, e atualize a variável 'BASE_DIR'.\")\n",
        "elif not os.path.exists(TRAIN_DIR) or not os.path.exists(VALIDATION_DIR):\n",
        "    print(f\"ERRO: Dentro de '{BASE_DIR}', os subdiretórios 'train' e/ou 'validation' não foram encontrados.\")\n",
        "    print(\"Certifique-se de que ambos existam e contenham as pastas das suas classes de imagens.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UzizhmT8QrfH",
        "outputId": "77f0b9b7-b8ce-4935-eb24-7b553fb35f66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ERRO: O diretório base do dataset 'meu_dataset_desastres' não foi encontrado.\n",
            "Por favor, crie este diretório, organize suas imagens de treino e validação dentro dele\n",
            "conforme a estrutura descrita acima, e atualize a variável 'BASE_DIR'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# 3. Preparação dos Geradores de Dados (`ImageDataGenerator`)\n",
        "\n",
        "O `ImageDataGenerator` é uma ferramenta do Keras para:\n",
        "\n",
        "- Carregar imagens diretamente do disco, organizadas em pastas por classe.\n",
        "- Aplicar **Data Augmentation** em tempo real durante o treinamento.\n",
        "\n",
        "### Data Augmentation\n",
        "\n",
        "- Aumenta artificialmente o dataset de treino aplicando transformações aleatórias (rotação, zoom etc.).\n",
        "- Ajuda o modelo a generalizar melhor e evitar overfitting.\n",
        "\n",
        "### Normalização\n",
        "\n",
        "- O parâmetro `rescale=1./255` normaliza os valores dos pixels das imagens para o intervalo `[0,1]`.\n",
        "\n",
        "### Geradores\n",
        "\n",
        "- `train_generator`: Aplica data augmentation e normalização.\n",
        "- `validation_generator`: Aplica apenas normalização.\n",
        "- `flow_from_directory`: Carrega as imagens e infere as classes a partir das subpastas.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "yPaCy_7_jGcd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Configuração do Data Augmentation para o conjunto de treino\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=30,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "# Apenas rescaling para o conjunto de validação\n",
        "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Inicialização dos geradores e NUM_CLASSES\n",
        "train_generator = None\n",
        "validation_generator = None\n",
        "NUM_CLASSES = 0\n",
        "\n",
        "# Tenta criar o gerador de treino\n",
        "if os.path.exists(TRAIN_DIR) and len(os.listdir(TRAIN_DIR)) > 0:\n",
        "    try:\n",
        "        train_generator = train_datagen.flow_from_directory(\n",
        "            TRAIN_DIR,\n",
        "            target_size=IMAGE_SIZE,\n",
        "            batch_size=BATCH_SIZE,\n",
        "            class_mode='categorical', # Para classificação multi-classe\n",
        "            shuffle=True\n",
        "        )\n",
        "        NUM_CLASSES = train_generator.num_classes # Obtém o número de classes\n",
        "        print(f\"Encontradas {train_generator.samples} imagens de treino pertencentes a {NUM_CLASSES} classes.\")\n",
        "        print(f\"Índices das classes de treino: {train_generator.class_indices}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Erro ao criar o gerador de treino: {e}\")\n",
        "else:\n",
        "    print(f\"Diretório de treino '{TRAIN_DIR}' não encontrado ou está vazio. Gerador de treino não criado.\")\n",
        "\n",
        "# Tenta criar o gerador de validação\n",
        "if os.path.exists(VALIDATION_DIR) and len(os.listdir(VALIDATION_DIR)) > 0:\n",
        "    try:\n",
        "        validation_generator = validation_datagen.flow_from_directory(\n",
        "            VALIDATION_DIR,\n",
        "            target_size=IMAGE_SIZE,\n",
        "            batch_size=BATCH_SIZE,\n",
        "            class_mode='categorical',\n",
        "            shuffle=False # Não embaralhar dados de validação\n",
        "        )\n",
        "        print(f\"Encontradas {validation_generator.samples} imagens de validação.\")\n",
        "        print(f\"Índices das classes de validação: {validation_generator.class_indices}\")\n",
        "        if train_generator and validation_generator.num_classes > 0 and validation_generator.class_indices != train_generator.class_indices:\n",
        "            print(\"ALERTA: Mapeamentos de classes entre treino e validação são diferentes!\")\n",
        "    except Exception as e:\n",
        "        print(f\"Erro ao criar o gerador de validação: {e}\")\n",
        "else:\n",
        "    print(f\"Diretório de validação '{VALIDATION_DIR}' não encontrado ou está vazio. Gerador de validação não criado.\")\n"
      ],
      "metadata": {
        "id": "QN2JEwegQ6t-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# 4. Visualização de Amostras de Imagens (Opcional)\n",
        "\n",
        "É uma boa prática visualizar algumas imagens do dataset, especialmente após o **Data Augmentation**, para garantir que estão sendo carregadas e processadas corretamente.\n"
      ],
      "metadata": {
        "id": "xy39VUZljPEF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "if train_generator:\n",
        "    def plot_sample_images(data_generator):\n",
        "        \"\"\"Plota um grid de imagens de amostra do gerador.\"\"\"\n",
        "        sample_images, sample_labels = next(data_generator)\n",
        "        plt.figure(figsize=(12, 10))\n",
        "        class_names = list(data_generator.class_indices.keys())\n",
        "\n",
        "        for i in range(min(9, len(sample_images))): # Mostra até 9 imagens\n",
        "            plt.subplot(3, 3, i + 1)\n",
        "            plt.imshow(sample_images[i])\n",
        "            class_index = np.argmax(sample_labels[i])\n",
        "            plt.title(class_names[class_index])\n",
        "            plt.axis('off')\n",
        "        plt.suptitle(\"Amostra de Imagens do Conjunto de Treino (com Data Augmentation)\", fontsize=16)\n",
        "        plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
        "        plt.show()\n",
        "\n",
        "    plot_sample_images(train_generator)\n",
        "else:\n",
        "    print(\"Gerador de treino não disponível. Não é possível mostrar imagens de amostra.\")\n"
      ],
      "metadata": {
        "id": "EFHdjDqUSDa3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "# 5. Construção do Modelo de Rede Neural Convolucional (CNN)\n",
        "\n",
        "Uma arquitetura CNN simples, ideal para começar.\n",
        "\n",
        "### Componentes:\n",
        "\n",
        "- `Conv2D`: Extrai características como bordas e texturas.\n",
        "- `MaxPooling2D`: Reduz a dimensionalidade, mantendo informações importantes.\n",
        "- `Flatten`: Transforma a saída 2D/3D em um vetor 1D.\n",
        "- `Dense`: Camadas totalmente conectadas para classificação.\n",
        "- `Dropout`: Regularização para prevenir overfitting, desativando aleatoriamente neurônios durante o treinamento.\n"
      ],
      "metadata": {
        "id": "GvPbPut3jR2F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model = None\n",
        "if NUM_CLASSES > 0:\n",
        "    model = Sequential([\n",
        "        layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu',\n",
        "                      input_shape=(IMAGE_WIDTH, IMAGE_HEIGHT, IMAGE_CHANNELS),\n",
        "                      padding='same'),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "        layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu', padding='same'),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "        layers.Conv2D(filters=128, kernel_size=(3, 3), activation='relu', padding='same'),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "        layers.Flatten(),\n",
        "\n",
        "        layers.Dense(units=512, activation='relu'),\n",
        "        layers.Dropout(0.5), # Dropout de 50%\n",
        "\n",
        "        layers.Dense(units=NUM_CLASSES, activation='softmax') # Camada de saída\n",
        "    ])\n",
        "\n",
        "    print(\"\\nArquitetura do Modelo:\")\n",
        "    model.summary() # Exibe um resumo da arquitetura do modelo\n",
        "else:\n",
        "    print(\"ERRO: NUM_CLASSES é zero. Modelo não pode ser construído.\")\n",
        "    print(\"Verifique os diretórios de treino e os caminhos.\")\n"
      ],
      "metadata": {
        "id": "ks92DXOTSHau"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# 6. Compilação e Treinamento do Modelo\n",
        "\n",
        "### Compilação\n",
        "\n",
        "- **Otimizador (`optimizer`)**: `adam` é uma escolha popular e eficiente.\n",
        "- **Função de Perda (`loss`)**: `categorical_crossentropy` para classificação multi-classe com *one-hot encoding*.\n",
        "- **Métricas (`metrics`)**: `accuracy` é comum para tarefas de classificação.\n",
        "\n",
        "### Callbacks\n",
        "\n",
        "- `EarlyStopping`: Interrompe o treinamento se a performance não melhorar após certo número de épocas.\n",
        "- `ModelCheckpoint`: Salva o modelo com a melhor performance em uma métrica.\n",
        "\n",
        "### Treinamento com `model.fit`\n",
        "\n",
        "- `train_generator`: Dados de treino.\n",
        "- `epochs`: Número de épocas.\n",
        "- `validation_data`: Dados de validação.\n",
        "- `callbacks`: Lista de callbacks usados.\n"
      ],
      "metadata": {
        "id": "zk1okQ4yjVnO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "history = None # Para armazenar o histórico de treinamento\n",
        "\n",
        "if model and train_generator and validation_generator:\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    print(\"\\nIniciando o treinamento do modelo...\")\n",
        "\n",
        "    # Definição dos callbacks\n",
        "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, verbose=1, restore_best_weights=True)\n",
        "    model_checkpoint = ModelCheckpoint(\n",
        "        'best_disaster_classifier_model.keras', # Nome do arquivo para salvar o melhor modelo\n",
        "        save_best_only=True,\n",
        "        monitor='val_accuracy',\n",
        "        mode='max', # Queremos maximizar a acurácia de validação\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    # Treinamento do modelo\n",
        "    history = model.fit(\n",
        "        train_generator,\n",
        "        epochs=EPOCHS,\n",
        "        validation_data=validation_generator,\n",
        "        callbacks=[early_stopping, model_checkpoint]\n",
        "    )\n",
        "    print(\"Treinamento concluído.\")\n",
        "\n",
        "    # Carregar os melhores pesos salvos pelo ModelCheckpoint\n",
        "    if os.path.exists('best_disaster_classifier_model.keras'):\n",
        "        print(\"Carregando o melhor modelo salvo ('best_disaster_classifier_model.keras').\")\n",
        "        model = keras.models.load_model('best_disaster_classifier_model.keras')\n",
        "else:\n",
        "    print(\"ERRO: Treinamento não pode ser iniciado. Verifique o modelo e os geradores de dados.\")\n"
      ],
      "metadata": {
        "id": "H_9maoJlSK6f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# 7. Avaliação do Desempenho do Modelo\n",
        "\n",
        "Após o treinamento, avaliamos o desempenho no conjunto de validação.\n",
        "\n",
        "### Gráficos de Acurácia e Perda\n",
        "\n",
        "- Mostram como a acurácia e a perda evoluíram nas épocas.\n",
        "- Ajudam a identificar **overfitting** ou **underfitting**.\n",
        "\n",
        "### Métricas\n",
        "\n",
        "- `model.evaluate`: Avalia o modelo.\n",
        "- **Matriz de Confusão**: Mostra erros de classificação por classe.\n",
        "- **Relatório de Classificação (`classification_report`)**:\n",
        "  - **Precisão (Precision)**: Correção das previsões de uma classe.\n",
        "  - **Recall**: Cobertura das instâncias reais de uma classe.\n",
        "  - **F1-Score**: Média harmônica entre precisão e recall.\n",
        "  - **Support**: Número real de amostras por classe.\n"
      ],
      "metadata": {
        "id": "9Dntd6CAjY69"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "if history and model and validation_generator:\n",
        "    print(\"\\nAvaliando o desempenho do modelo treinado...\")\n",
        "\n",
        "    # Obter dados do histórico de treinamento\n",
        "    acc = history.history.get('accuracy', [])\n",
        "    val_acc = history.history.get('val_accuracy', [])\n",
        "    loss = history.history.get('loss', [])\n",
        "    val_loss = history.history.get('val_loss', [])\n",
        "    epochs_range = range(len(acc))\n",
        "\n",
        "    # Plotar gráficos\n",
        "    plt.figure(figsize=(14, 5))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    if acc and val_acc:\n",
        "        plt.plot(epochs_range, acc, label='Acurácia de Treino')\n",
        "        plt.plot(epochs_range, val_acc, label='Acurácia de Validação')\n",
        "        plt.legend(loc='lower right')\n",
        "        plt.title('Acurácia de Treino e Validação')\n",
        "    else:\n",
        "        plt.title('Dados de Acurácia não disponíveis')\n",
        "    plt.xlabel('Épocas'); plt.ylabel('Acurácia')\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    if loss and val_loss:\n",
        "        plt.plot(epochs_range, loss, label='Perda de Treino')\n",
        "        plt.plot(epochs_range, val_loss, label='Perda de Validação')\n",
        "        plt.legend(loc='upper right')\n",
        "        plt.title('Perda de Treino e Validação')\n",
        "    else:\n",
        "        plt.title('Dados de Perda não disponíveis')\n",
        "    plt.xlabel('Épocas'); plt.ylabel('Perda')\n",
        "    plt.show()\n",
        "\n",
        "    # Avaliação final no conjunto de validação\n",
        "    print(\"\\nPerformance final no conjunto de validação:\")\n",
        "    try:\n",
        "        loss_val, accuracy_val = model.evaluate(validation_generator, verbose=0)\n",
        "        print(f\"  Perda de Validação: {loss_val:.4f}\")\n",
        "        print(f\"  Acurácia de Validação: {accuracy_val*100:.2f}%\")\n",
        "\n",
        "        # Predições para Matriz de Confusão e Relatório\n",
        "        validation_generator.reset()\n",
        "        Y_pred_probs = model.predict(validation_generator)\n",
        "        y_pred_classes = np.argmax(Y_pred_probs, axis=1)\n",
        "        y_true_classes = validation_generator.classes\n",
        "        class_names = list(validation_generator.class_indices.keys())\n",
        "\n",
        "        # Matriz de Confusão\n",
        "        from sklearn.metrics import confusion_matrix, classification_report\n",
        "        cm = confusion_matrix(y_true_classes, y_pred_classes)\n",
        "        plt.figure(figsize=(10, 8))\n",
        "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                    xticklabels=class_names, yticklabels=class_names)\n",
        "        plt.title('Matriz de Confusão no Conjunto de Validação')\n",
        "        plt.ylabel('Classe Verdadeira'); plt.xlabel('Classe Predita')\n",
        "        plt.show()\n",
        "\n",
        "        # Relatório de Classificação\n",
        "        print(\"\\nRelatório de Classificação no Conjunto de Validação:\")\n",
        "        print(classification_report(y_true_classes, y_pred_classes, target_names=class_names, zero_division=0))\n",
        "    except Exception as e:\n",
        "        print(f\"Erro durante a avaliação no conjunto de validação: {e}\")\n",
        "else:\n",
        "    print(\"Avaliação não pode ser realizada. Modelo não treinado ou dados de validação ausentes.\")\n"
      ],
      "metadata": {
        "id": "I27O2DeASO6L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# 8. Teste do Modelo com Novas Imagens (Exemplo)\n",
        "\n",
        "Demonstra como usar o modelo treinado para prever uma nova imagem.\n",
        "\n",
        "### Passos:\n",
        "\n",
        "1. Carregar a imagem do disco.\n",
        "2. Redimensionar para `IMAGE_SIZE`.\n",
        "3. Converter para array NumPy.\n",
        "4. Normalizar os pixels (dividir por `255.0`).\n",
        "5. Expandir dimensões para formar um batch.\n",
        "6. Usar `model.predict()` para prever.\n",
        "7. Identificar a classe com maior probabilidade.\n"
      ],
      "metadata": {
        "id": "rm6dA1n4jbgn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def predict_single_image(image_path, loaded_model, class_names_list):\n",
        "    \"\"\"Carrega, pré-processa, prevê e exibe uma única imagem.\"\"\"\n",
        "    try:\n",
        "        img = keras.preprocessing.image.load_img(image_path, target_size=IMAGE_SIZE)\n",
        "        img_array = keras.preprocessing.image.img_to_array(img)\n",
        "        img_array /= 255.0 # Normaliza\n",
        "        img_array_expanded = tf.expand_dims(img_array, 0) # Cria um batch\n",
        "\n",
        "        predictions = loaded_model.predict(img_array_expanded)\n",
        "        predicted_class_index = np.argmax(predictions[0])\n",
        "        predicted_class_name = class_names_list[predicted_class_index]\n",
        "        confidence = 100 * np.max(predictions[0])\n",
        "\n",
        "        plt.figure(figsize=(6,6))\n",
        "        plt.imshow(img) # Mostra a imagem original\n",
        "        plt.title(f\"Predição: {predicted_class_name}\\nConfiança: {confidence:.2f}%\", fontsize=14)\n",
        "        plt.axis(\"off\"); plt.show()\n",
        "        print(f\"Imagem '{os.path.basename(image_path)}' classificada como: {predicted_class_name} (Confiança: {confidence:.2f}%)\")\n",
        "        return predicted_class_name, confidence\n",
        "    except FileNotFoundError:\n",
        "        print(f\"ERRO: Imagem não encontrada em '{image_path}'\"); return None, None\n",
        "    except Exception as e:\n",
        "        print(f\"ERRO ao processar imagem '{image_path}': {e}\"); return None, None\n",
        "\n",
        "# Testar com uma imagem de exemplo\n",
        "if os.path.exists('best_disaster_classifier_model.keras') and validation_generator:\n",
        "    print(\"\\n--- Testando o modelo treinado com uma imagem de exemplo ---\")\n",
        "    loaded_model_for_testing = keras.models.load_model('best_disaster_classifier_model.keras')\n",
        "    class_names_for_testing = list(validation_generator.class_indices.keys())\n",
        "\n",
        "    example_image_path = None\n",
        "    if os.path.exists(VALIDATION_DIR) and len(os.listdir(VALIDATION_DIR)) > 0:\n",
        "        try:\n",
        "            first_class_folder_name = os.listdir(VALIDATION_DIR)[0]\n",
        "            first_class_path = os.path.join(VALIDATION_DIR, first_class_folder_name)\n",
        "            if os.path.isdir(first_class_path) and len(os.listdir(first_class_path)) > 0:\n",
        "                first_image_name = os.listdir(first_class_path)[0]\n",
        "                example_image_path = os.path.join(first_class_path, first_image_name)\n",
        "        except Exception as e:\n",
        "            print(f\"Não foi possível selecionar imagem de exemplo automaticamente: {e}\")\n",
        "\n",
        "    if example_image_path and os.path.exists(example_image_path):\n",
        "        print(f\"Usando imagem de exemplo para teste: '{example_image_path}'\")\n",
        "        predict_single_image(example_image_path, loaded_model_for_testing, class_names_for_testing)\n",
        "    else:\n",
        "        print(\"Não foi possível encontrar imagem de exemplo. Forneça o caminho manualmente.\")\n",
        "        # test_image_manual_path = 'caminho/para/sua/imagem.jpg' # DESCOMENTE E AJUSTE\n",
        "        # if os.path.exists(test_image_manual_path):\n",
        "        #   predict_single_image(test_image_manual_path, loaded_model_for_testing, class_names_for_testing)\n",
        "else:\n",
        "    print(\"\\nModelo 'best_disaster_classifier_model.keras' ou gerador de validação não disponíveis.\")\n",
        "    print(\"Pule o teste ou treine o modelo primeiro.\")\n",
        "\n",
        "print(\"\\n--- Fim do Notebook ---\")"
      ],
      "metadata": {
        "id": "81zoWdhwSSeB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "bn0BcRZ5QqXu"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}